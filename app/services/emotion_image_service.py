import base64
import json
from openai import OpenAI
import os
from dotenv import load_dotenv
load_dotenv()


async def analyze_emotion_service(image_bytes: bytes, target_emotion: str):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # targetEmotion ëŒ€ë¬¸ìë¡œ í†µì¼
    target_emotion = target_emotion.upper()

    # Base64 ë³€í™˜
    base64_image = base64.b64encode(image_bytes).decode()

    # ----------------------------
    # ğŸ”¥ ìµœì¢… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
    # ----------------------------
    prompt = f"""
ë‹¹ì‹ ì€ ê°ì • ì¸ì‹ê³¼ ê°ì • í‘œí˜„ì„ ì–´ë ¤ì›Œí•˜ëŠ” ì‚¬ëŒë“¤ì„ ë•ëŠ” â€œê°ì • í‘œí˜„ ì½”ì¹˜â€ì…ë‹ˆë‹¤.  

ì‚¬ìš©ìê°€ í‘œí˜„í•˜ë ¤ê³  í•˜ëŠ” ëª©í‘œ ê°ì •(targetEmotion)ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- targetEmotion: "{target_emotion}"

ì—…ë¡œë“œëœ ì–¼êµ´ í‘œì •ì„ ë¶„ì„í•œ ë’¤ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

{{
  "detectedEmotion": "JOY" | "SADNESS" | "ANGER" | "SURPRISE" | "ANXIETY",
  "feedback": "í•œêµ­ì–´ë¡œ ëœ ìƒì„¸ í”¼ë“œë°±"
}}

ê·œì¹™:
1. detectedEmotionì€ ìœ„ 5ê°œ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ.
2. feedbackì€ ë‹¤ìŒ ë‚´ìš©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•¨:
   - ì‚¬ì§„ ì† ì–¼êµ´ íŠ¹ì§•(ëˆˆ, ì…, ëˆˆì¹ ë“±)ì„ ê¸°ì¤€ìœ¼ë¡œ ì–´ë–¤ ê°ì •ì²˜ëŸ¼ ë³´ì˜€ëŠ”ì§€ ë¶„ì„
   - detectedEmotionê³¼ targetEmotionì´ ê°™ë‹¤ë©´:
        - ì–´ë–¤ ìš”ì†Œ ë•ë¶„ì— ê°ì •ì´ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ì§€ ì¹­ì°¬
        - ë”ìš± ìì—°ìŠ¤ëŸ½ê²Œ / ë” ê°•í•˜ê²Œ í‘œí˜„í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì  ì¡°ì–¸
   - detectedEmotionê³¼ targetEmotionì´ ë‹¤ë¥´ë‹¤ë©´:
        - ì–´ë–¤ ìš”ì†Œ ë•Œë¬¸ì— ë‹¤ë¥¸ ê°ì •ìœ¼ë¡œ ë³´ì˜€ëŠ”ì§€ ì„¤ëª…
        - targetEmotionì— ë” ê°€ê¹Œì›Œì§€ê¸° ìœ„í•´ ì–´ë–¤ ì¡°ì •ì´ í•„ìš”í•œì§€ ì¡°ì–¸
3. ì „ì²´ í”¼ë“œë°±ì€ ì¹œì ˆí•˜ê³  ì½”ì¹­í•˜ë“¯ ë§í•  ê²ƒ.
4. JSON ì´ì™¸ì˜ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.
5. ì½”ë“œë¸”ë¡(```json```) ì‚¬ìš© ê¸ˆì§€.
6. ì‚¬ì§„ì´ë¼ëŠ” ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€.
7. ê°ì •ì„ í•œêµ­ì–´ë¡œ í‘œí˜„í•  ê²ƒ(ê¸°ì¨, ìŠ¬í””, ë¶„ë…¸, ë†€ëŒ, ë¶ˆì•ˆ).
8. feedbackì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë§Œ ì‚¬ìš©
"""

    # ----------------------------
    # ğŸ”¥ OpenAI Vision í˜¸ì¶œ
    # ----------------------------
    response = client.chat.completions.create(
        model="gpt-4o-mini",   # ì´ë¯¸ì§€ ë¶„ì„ ê°€ëŠ¥í•œ ìµœì‹  ì†Œí˜• ëª¨ë¸
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ]
    )

    # ----------------------------
    # ğŸ”¥ GPT ì‘ë‹µ íŒŒì‹±
    # ----------------------------
    result_text = response.choices[0].message.content

    try:
        gpt_json = json.loads(result_text)
    except Exception:
        raise ValueError(f"GPT JSON íŒŒì‹± ì‹¤íŒ¨: {result_text}")

    detected = gpt_json["detectedEmotion"]

    # ì ìˆ˜ ê³„ì‚°
    score = 100 if detected == target_emotion else 40

    # ìµœì¢… ë°˜í™˜
    return {
        "targetEmotion": target_emotion,
        "detectedEmotion": detected,
        "score": score,
        "feedback": gpt_json["feedback"]
    }
