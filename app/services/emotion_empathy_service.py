import json
import random
import os
from sqlmodel import Session
from fastapi import Request
from sqlmodel import Session
from openai import OpenAI
from dotenv import load_dotenv
import chromadb

from app.models.enums import EmotionLabel
from app.schemas.emotion_empathy_schema import (
    SelectedEmotionQuery,
    EmpathyEvaluateRequest,
)
from app.utils.jwt_provider import verify_access_token
from app.models.empathy_training_result import EmpathyTrainingResult
from app.models.empathy_type import EmpathyType

#ì„œë¹„ìŠ¤

load_dotenv()


# -------------------------------------------------------
# â­ 1) ê³µê° ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì„œë¹„ìŠ¤
# -------------------------------------------------------
async def create_empathy_scenario_service(
    *,
    query: SelectedEmotionQuery,
):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # Emotionì´ RANDOMì´ë©´ ëžœë¤ ì„ íƒ
    if query.option == EmotionLabel.RANDOM:
        emotions = [e for e in EmotionLabel if e != EmotionLabel.RANDOM]
        chosen_emotion = random.choice(emotions)
    else:
        chosen_emotion = query.option

    # -----------------------------
    # ðŸ”¥ Prompt ì„¤ê³„
    # -----------------------------
    prompt = f"""
    ë‹¹ì‹ ì€ ê³µê° ëŠ¥ë ¥ì„ ê¸°ë¥´ëŠ” ì—°ìŠµì„ ë•ëŠ” "ìƒí™© ìƒì„± ì „ë¬¸ê°€"ìž…ë‹ˆë‹¤.

    ì•„ëž˜ ê°ì •ì— í•´ë‹¹í•˜ëŠ”, ì‚¬ìš©ìžê°€ ê³µê° ì—°ìŠµì— ì‚¬ìš©í•  ì§§ê³  êµ¬ì²´ì ì¸ ìƒí™© ì„¤ëª…ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

    ê°ì •:
    - {chosen_emotion.name}

    ì¶œë ¥ í˜•ì‹(JSON):
    {{
        "emotion": "JOY" | "SAD" | "ANGER" | "LOVE" | "FEAR",
        "scenario": "ê³µê°ì´ í•„ìš”í•œ ì±„íŒ… í…ìŠ¤íŠ¸"
    }}

    ê·œì¹™:
    1. ê°ì •ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ê³  ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ê°ì •ì´ ë“œëŸ¬ë‚˜ê²Œ í‘œí˜„í•  ê²ƒ.
    2. í˜„ì‹¤ì ì´ê³  ê³µê° ê°€ëŠ¥í•œ ì¹´í†¡/ë©”ì‹ ì € ìŠ¤íƒ€ì¼ ëŒ€í™”ë§Œ ìž‘ì„±í•  ê²ƒ.
    3. ëª¨ë“  ë©”ì‹œì§€ëŠ” í•œêµ­ì–´ë¡œ.
    4. JSONë§Œ ì¶œë ¥. ì½”ë“œ ë¸”ë¡ ê¸ˆì§€.
    """

    # -----------------------------
    # ðŸ”¥ OpenAI í˜¸ì¶œ
    # -----------------------------
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    # GPT ì‘ë‹µ í…ìŠ¤íŠ¸
    result_text = response.choices[0].message.content

    try:
        gpt_json = json.loads(result_text)
    except Exception:
        raise ValueError(f"GPT JSON íŒŒì‹± ì‹¤íŒ¨: {result_text}")

    scenario_text = gpt_json["scenario"]

    return {
    "emotion": chosen_emotion.name,
    "scenario": scenario_text
}

# -------------------------------------------------------
# â­ 2) ê³µê° ë©”ì‹œì§€ í‰ê°€ ì„œë¹„ìŠ¤
# -------------------------------------------------------
async def evaluate_empathy_message_service(
    *,
    body: EmpathyEvaluateRequest,
    token: str | None,
    session: Session
):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    emotion = body.emotion # ì„ íƒí•œ ê°ì •ë„ ì €ìž¥í•´ì•¼í•˜ê¸°ë•Œë¬¸ì— ì¶”ê°€
    scenario = body.scenario
    user_message = body.userMessage

    # -----------------------------
    # ðŸ”¥ Prompt ì„¤ê³„
    # -----------------------------
    system_prompt = """
    ë‹¹ì‹ ì€ ê³µê° ëŠ¥ë ¥ ì½”ì¹­ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.

    ì•„ëž˜ ì‹œë‚˜ë¦¬ì˜¤ì™€ ì‚¬ìš©ìžì˜ ê³µê° ë©”ì‹œì§€ë¥¼ í‰ê°€í•œ ë’¤,
    ë°˜ë“œì‹œ ì•„ëž˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

    {
    "score": 0~100,
    "feedback": "í•œêµ­ì–´ ìƒì„¸ í”¼ë“œë°±"
    }

    ê·œì¹™:
    1. scoreëŠ” 0ì—ì„œ 100 ì‚¬ì´ì˜ ìˆ«ìžë§Œ ì¶œë ¥í•  ê²ƒ.
    2. feedbackì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•  ê²ƒ:
    - ê³µê°ì´ ìž˜ ëœ ë¶€ë¶„
    - ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸
    - ë§Œì•½ ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìžˆë‹¤ë©´ ë¶€ì¡±í•œ ë¶€ë¶„ë„ í¬í•¨
    4. ì „ì²´ í”¼ë“œë°±ì€ ì¹œì ˆí•˜ê³  ì½”ì¹­í•˜ë“¯ ìž‘ì„±í•  ê²ƒ.
    5. JSON ì´ì™¸ì˜ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.
    6. ì½”ë“œë¸”ë¡ ì‚¬ìš© ê¸ˆì§€.
    7. í•œêµ­ì–´ë§Œ ì‚¬ìš©í•  ê²ƒ.
    """
    
    user_prompt = f"""
    ì‹œë‚˜ë¦¬ì˜¤:
    "{scenario}"

    ì‚¬ìš©ìžì˜ ë©”ì‹œì§€:
    "{user_message}"
    """

    # -----------------------------
    # ðŸ”¥ OpenAI í˜¸ì¶œ
    # -----------------------------
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    )

    result_text = response.choices[0].message.content

    # GPTì‘ë‹µ JSON íŒŒì‹±
    try:
        gpt_json = json.loads(result_text)
    except Exception:
        raise ValueError(f"GPT JSON íŒŒì‹± ì‹¤íŒ¨: {result_text}")

    score = gpt_json["score"]
    feedback = gpt_json["feedback"]

    #  access_token â†’ user_id íŒŒì‹±
    # -------------------------------------------------------
    user_id = None

    if token:
        payload = verify_access_token(token)  
        if payload:
            user_id = int(payload.get("sub"))  


    predicted_label = None
    
    # ðŸ”¥ user_id ìžˆìœ¼ë©´ DB ì €ìž¥
    if user_id:
        predicted_label = classify_empathy(client, user_message)
        type_history = EmpathyType(
            user_id=user_id,
            empathy_category=predicted_label
        )
        session.add(type_history)
        session.commit()
        session.refresh(type_history)
        
        training_history = EmpathyTrainingResult(
            user_id=user_id,
            emotion_label=emotion,
            scenario_text=scenario,
            user_reply=user_message,
            empathy_score = score,
            feedback=feedback
        )
        session.add(training_history)
        session.commit()
        session.refresh(training_history)

    # ì ìˆ˜ì™€ gptí”¼ë“œë°± ìµœì¢… ë°˜í™˜
    return {
        "score": score,
        "feedback": feedback
    }


def embed(client:OpenAI, text: str):
    resp = client.embeddings.create(
        model="text-embedding-3-large",
        input=text,
    )
    return resp.data[0].embedding

# ðŸ‘‰ ì´ë¯¸ ë§Œë“¤ì–´ì§„ DBë§Œ ì‚¬ìš© (ì¸ë±ì‹±ì€ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ)
chroma_client = chromadb.PersistentClient(path="./chroma/db")
collection = chroma_client.get_or_create_collection(
    name="empathy_training",
)

def classify_empathy(client:OpenAI, user_text: str) -> str:
    user_vec = embed(client, user_text)

    results = collection.query(
        query_embeddings=[user_vec],
        n_results=5,
    )

    labels = [m["label"] for m in results["metadatas"][0]]
    return max(set(labels), key=labels.count)