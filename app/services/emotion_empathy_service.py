import random
import os
from typing import Dict, Tuple

from sqlmodel import Session
from openai import OpenAI
from dotenv import load_dotenv
import chromadb

from app.models.enums import EmotionLabel
from app.schemas.emotion_empathy_schema import (
    SelectedEmotionQuery,
    EmpathyEvaluateRequest,
)
from app.utils.jwt_provider import verify_access_token
from app.models.empathy_training_result import EmpathyTrainingResult
from app.models.empathy_type import EmpathyType

from langchain.memory import ConversationBufferWindowMemory

from app.services.emotion_empathy_chain import build_empathy_multi_chain

load_dotenv()

empathy_multi_chain = build_empathy_multi_chain(model_name="gpt-4o-mini")

empathy_user_memories: Dict[
    Tuple[int, str],
    ConversationBufferWindowMemory
] = {}


def get_or_create_empathy_memory(
    user_id: int,
    emotion: str
) -> ConversationBufferWindowMemory:
    key = (user_id, emotion)

    if key not in empathy_user_memories:
        empathy_user_memories[key] = ConversationBufferWindowMemory(
            k=5,  # ê°ì •ë³„ ìµœëŒ€ 5ê°œ
            input_key="user_message",
            output_key="feedback",
            memory_key="chat_history",
            return_messages=False
        )
        print(f"[INFO] ê³µê° ë©”ëª¨ë¦¬ ìƒì„± - user:{user_id}, emotion:{emotion}")

    return empathy_user_memories[key]


def reset_empathy_memory(user_id: int, emotion: str):
    key = (user_id, emotion)
    if key in empathy_user_memories:
        empathy_user_memories[key].clear()
        print(f"[INFO] ê³µê° ë©”ëª¨ë¦¬ ì´ˆê¸°í™” - user:{user_id}, emotion:{emotion}")


# -------------------------------------------------------
# 1) ê³µê° ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì„œë¹„ìŠ¤ (ë©€í‹°ì²´ì¸ ì ìš©)
# -------------------------------------------------------
async def create_empathy_scenario_service(
    *,
    query: SelectedEmotionQuery,
    token: str | None
):

    user_id = None
    if token:
        payload = verify_access_token(token)
        if payload:
            user_id = int(payload.get("sub"))
            reset_empathy_memory(user_id=user_id, emotion=query.option)

    # Emotionì´ RANDOMì´ë©´ ëžœë¤ ì„ íƒ
    if query.option == EmotionLabel.RANDOM:
        emotions = [e for e in EmotionLabel if e not in (EmotionLabel.RANDOM, EmotionLabel.NEUTRAL)]
        chosen_emotion = random.choice(emotions)
    else:
        chosen_emotion = query.option

    # âœ… ìˆ˜ì •: OpenAI í˜¸ì¶œ â†’ ë©€í‹°ì²´ì¸ í˜¸ì¶œ
    gpt_json = empathy_multi_chain.invoke(
        {"task": "scenario", "emotion": chosen_emotion.name}
    )

    # ì—ëŸ¬ ë°©ì–´
    if "error" in gpt_json:
        raise ValueError(gpt_json["error"])

    scenario_text = gpt_json["scenario"]

    return {
        "emotion": chosen_emotion.name,
        "scenario": scenario_text
    }


# -------------------------------------------------------
# â­ 2) ê³µê° ë©”ì‹œì§€ í‰ê°€ ì„œë¹„ìŠ¤ (ë©€í‹°ì²´ì¸ ì ìš©)
# -------------------------------------------------------
async def evaluate_empathy_message_service(
    *,
    body: EmpathyEvaluateRequest,
    token: str | None,
    session: Session
):
    # âœ… ìœ ì§€: embedding/Chroma ë¶„ë¥˜ìš© OpenAI clientëŠ” í•„ìš”
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    emotion = body.emotion
    scenario = body.scenario
    user_message = body.userMessage

    user_id = None
    if token:
        payload = verify_access_token(token)
        if payload:
            user_id = int(payload.get("sub"))

    memory = None
    chat_history = "ì´ì „ ì‹œë„ ì´ë ¥: ì—†ìŒ"

    if user_id:
        memory = get_or_create_empathy_memory(user_id, emotion)
        memory_vars = memory.load_memory_variables({})
        chat_history = memory_vars.get("chat_history") or "ì´ì „ ì‹œë„ ì´ë ¥: ì—†ìŒ"

    print(chat_history)

    gpt_json = empathy_multi_chain.invoke(
        {
            "task": "evaluate",
            "chat_history": chat_history,
            "scenario": scenario,
            "user_message": user_message,
        }
    )

    # ì—ëŸ¬ ì²˜ë¦¬
    if "error" in gpt_json:
        raise ValueError(gpt_json["error"])

    # ì ìˆ˜/í”¼ë“œë°± ì¶”ì¶œ
    score = gpt_json["score"]
    feedback = gpt_json["feedback"]

    # ë©”ëª¨ë¦¬ ì €ìž¥
    if memory:
        memory.save_context(
            {"user_message": user_message},
            {"feedback": f"ì ìˆ˜: {score}, í”¼ë“œë°±: {feedback}"}
        )

    # user_id ìžˆìœ¼ë©´ DB ì €ìž¥
    if user_id:
        predicted_label = classify_empathy(client, user_message)

        type_history = EmpathyType(
            user_id=user_id,
            empathy_category=predicted_label
        )
        session.add(type_history)
        session.commit()
        session.refresh(type_history)

        training_history = EmpathyTrainingResult(
            user_id=user_id,
            emotion_label=emotion,
            scenario_text=scenario,
            user_reply=user_message,
            empathy_score=score,
            feedback=feedback
        )
        session.add(training_history)
        session.commit()
        session.refresh(training_history)

    return {
        "score": score,
        "feedback": feedback
    }


# -------------------------------------------------------
# Embedding / Chroma ë¶„ë¥˜ (ê¸°ì¡´ ìœ ì§€)
# -------------------------------------------------------
def embed(client: OpenAI, text: str):
    resp = client.embeddings.create(
        model="text-embedding-3-large",
        input=text,
    )
    return resp.data[0].embedding


# ðŸ‘‰ ì´ë¯¸ ë§Œë“¤ì–´ì§„ DBë§Œ ì‚¬ìš© (ì¸ë±ì‹±ì€ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ)
chroma_client = chromadb.PersistentClient(path="./chroma/db")
collection = chroma_client.get_or_create_collection(
    name="empathy_training",
)


def classify_empathy(client: OpenAI, user_text: str) -> str:
    user_vec = embed(client, user_text)

    results = collection.query(
        query_embeddings=[user_vec],
        n_results=5,
    )

    labels = [m["label"] for m in results["metadatas"][0]]
    return max(set(labels), key=labels.count)
